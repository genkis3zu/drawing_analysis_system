# src/ui/pages/batch.py

import streamlit as st
import pandas as pd
import time
from pathlib import Path
from datetime import datetime
import sys

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent.parent.parent
sys.path.append(str(project_root))

from src.core.agent import create_agent_from_config
from src.utils.batch_processor import BatchProcessor
from src.utils.file_handler import FileHandler
from src.utils.excel_manager import ExcelManager
from src.ui.components import (
    FileUploader, ProgressTracker, NotificationManager, 
    MetricsDisplay, DataExporter, StatisticsChart
)

def show():
    """ãƒãƒƒãƒå‡¦ç†ãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    
    st.title("ğŸ”„ ãƒãƒƒãƒå‡¦ç†")
    st.markdown("è¤‡æ•°ã®å›³é¢ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬ã§å‡¦ç†ã—ã¾ã™ã€‚")
    
    # ã‚¿ãƒ–æ§‹æˆ
    tab1, tab2, tab3 = st.tabs(["ğŸ“ ãƒãƒƒãƒå®Ÿè¡Œ", "ğŸ“Š å‡¦ç†çµæœ", "ğŸ“ˆ çµ±è¨ˆãƒ»å±¥æ­´"])
    
    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¿ãƒ–ã®ç®¡ç†
    if 'active_batch_tab' not in st.session_state:
        st.session_state.active_batch_tab = "ğŸ“ ãƒãƒƒãƒå®Ÿè¡Œ"
    
    # ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆ
    if st.session_state.active_batch_tab == "ğŸ“ ãƒãƒƒãƒå®Ÿè¡Œ":
        with tab1:
            show_batch_execution_tab()
    elif st.session_state.active_batch_tab == "ğŸ“Š å‡¦ç†çµæœ":
        with tab2:
            show_batch_results_tab()
    else:
        with tab3:
            show_batch_statistics_tab()

def show_batch_execution_tab():
    """ãƒãƒƒãƒå®Ÿè¡Œã‚¿ãƒ–"""
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("ğŸ“‚ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š")
        
        # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        default_input = st.session_state.config.get('files.input_directory', 'data/input') if st.session_state.config else 'data/input'
        input_directory = st.text_input(
            "å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:",
            value=default_input,
            help="å‡¦ç†å¯¾è±¡ã®å›³é¢ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
        )
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªè¨­å®š
        default_output = st.session_state.config.get('files.output_directory', 'data/output') if st.session_state.config else 'data/output'
        output_directory = st.text_input(
            "å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª:",
            value=default_output,
            help="å‡¦ç†çµæœã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª"
        )
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªçŠ¶æ…‹ç¢ºèª
        check_directories(input_directory, output_directory)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§è¡¨ç¤º
        show_file_list(input_directory)
        
        # ãƒãƒƒãƒå‡¦ç†è¨­å®š
        st.subheader("âš™ï¸ ãƒãƒƒãƒå‡¦ç†è¨­å®š")
        
        col_set1, col_set2 = st.columns(2)
        
        with col_set1:
            batch_size = st.number_input(
                "ãƒãƒƒãƒã‚µã‚¤ã‚º:",
                min_value=1,
                max_value=50,
                value=10,
                help="åŒæ™‚ã«å‡¦ç†ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«æ•°"
            )
            
            max_workers = st.number_input(
                "ä¸¦åˆ—å‡¦ç†æ•°:",
                min_value=1,
                max_value=8,
                value=4,
                help="ä¸¦åˆ—ã§å®Ÿè¡Œã™ã‚‹ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°"
            )
        
        with col_set2:
            timeout_minutes = st.number_input(
                "ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆåˆ†ï¼‰:",
                min_value=1,
                max_value=60,
                value=5,
                help="1ãƒ•ã‚¡ã‚¤ãƒ«ã‚ãŸã‚Šã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ™‚é–“"
            )
            
            retry_attempts = st.number_input(
                "ãƒªãƒˆãƒ©ã‚¤å›æ•°:",
                min_value=0,
                max_value=5,
                value=2,
                help="å¤±æ•—æ™‚ã®ãƒªãƒˆãƒ©ã‚¤å›æ•°"
            )
        
        # å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³
        with st.expander("ğŸ”§ å‡¦ç†ã‚ªãƒ—ã‚·ãƒ§ãƒ³", expanded=False):
            
            # è£½å“ã‚¿ã‚¤ãƒ—è‡ªå‹•åˆ¤å®š
            auto_product_type = st.checkbox(
                "è£½å“ã‚¿ã‚¤ãƒ—è‡ªå‹•åˆ¤å®š",
                value=True,
                help="ãƒ•ã‚¡ã‚¤ãƒ«åã‚„å†…å®¹ã‹ã‚‰è£½å“ã‚¿ã‚¤ãƒ—ã‚’è‡ªå‹•åˆ¤å®š"
            )
            
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè£½å“ã‚¿ã‚¤ãƒ—
            if not auto_product_type:
                default_product_type = st.selectbox(
                    "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè£½å“ã‚¿ã‚¤ãƒ—:",
                    ["æ©Ÿæ¢°éƒ¨å“", "é›»æ°—éƒ¨å“", "çµ„ç«‹å›³", "é…ç·šå›³", "ãã®ä»–"],
                    help="è‡ªå‹•åˆ¤å®šã—ãªã„å ´åˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ"
                )
            else:
                default_product_type = None
            
            # ã‚¨ãƒ©ãƒ¼å‡¦ç†
            error_handling = st.selectbox(
                "ã‚¨ãƒ©ãƒ¼å‡¦ç†:",
                ["ç¶šè¡Œ", "åœæ­¢", "ã‚¹ã‚­ãƒƒãƒ—"],
                index=0,
                help="ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®å‡¦ç†æ–¹æ³•"
            )
            
            # å‡ºåŠ›å½¢å¼
            output_formats = st.multiselect(
                "å‡ºåŠ›å½¢å¼:",
                ["JSON", "Excel", "CSV"],
                default=["JSON", "Excel"],
                help="å‡¦ç†çµæœã®å‡ºåŠ›å½¢å¼"
            )
        
        # ãƒãƒƒãƒå®Ÿè¡Œãƒœã‚¿ãƒ³
        st.markdown("---")
        
        if st.button("ğŸš€ ãƒãƒƒãƒå‡¦ç†é–‹å§‹", type="primary", use_container_width=True):
            execute_batch_processing(
                input_directory,
                output_directory,
                {
                    'batch_size': batch_size,
                    'max_workers': max_workers,
                    'timeout_minutes': timeout_minutes,
                    'retry_attempts': retry_attempts,
                    'auto_product_type': auto_product_type,
                    'default_product_type': default_product_type,
                    'error_handling': error_handling,
                    'output_formats': output_formats
                }
            )
    
    with col2:
        st.subheader("ğŸ“Š å‡¦ç†çŠ¶æ³")
        
        # ç¾åœ¨ã®å‡¦ç†çŠ¶æ³
        if st.session_state.get('batch_processing', False):
            show_batch_progress()
        else:
            show_batch_summary()
        
        # æœ€è¿‘ã®ãƒãƒƒãƒå±¥æ­´
        show_recent_batch_history()

def check_directories(input_dir, output_dir):
    """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª"""
    
    col1, col2 = st.columns(2)
    
    with col1:
        input_path = Path(input_dir)
        if input_path.exists():
            file_count = len(list(input_path.glob('*')))
            st.success(f"âœ… å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨ ({file_count}ãƒ•ã‚¡ã‚¤ãƒ«)")
        else:
            st.error("âŒ å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
    
    with col2:
        output_path = Path(output_dir)
        if output_path.exists():
            st.success("âœ… å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå­˜åœ¨")
        else:
            st.warning("âš ï¸ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¾ã™")

def show_file_list(input_directory):
    """å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’è¡¨ç¤º"""
    
    with st.expander("ğŸ“‹ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§", expanded=False):
        try:
            input_path = Path(input_directory)
            if not input_path.exists():
                st.warning("ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return
            
            # å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
            supported_formats = ['.jpg', '.jpeg', '.png', '.pdf', '.tiff']
            files = []
            
            for ext in supported_formats:
                files.extend(list(input_path.glob(f"*{ext}")))
                files.extend(list(input_path.glob(f"*{ext.upper()}")))
            
            if files:
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ãƒ†ãƒ¼ãƒ–ãƒ«
                file_data = []
                for file_path in sorted(files):
                    stat = file_path.stat()
                    file_data.append({
                        'ãƒ•ã‚¡ã‚¤ãƒ«å': file_path.name,
                        'ã‚µã‚¤ã‚º': f"{stat.st_size / 1024:.1f} KB",
                        'æ›´æ–°æ—¥': datetime.fromtimestamp(stat.st_mtime).strftime('%Y-%m-%d %H:%M'),
                        'å½¢å¼': file_path.suffix.upper()
                    })
                
                df = pd.DataFrame(file_data)
                st.dataframe(df, use_container_width=True, hide_index=True)
                
                st.info(f"ğŸ“ å‡¦ç†å¯¾è±¡: {len(files)}ãƒ•ã‚¡ã‚¤ãƒ«")
            else:
                st.warning(f"å¯¾å¿œãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“\nå¯¾å¿œå½¢å¼: {', '.join(supported_formats)}")
        
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

def show_batch_progress():
    """ãƒãƒƒãƒå‡¦ç†é€²æ—ã‚’è¡¨ç¤º"""
    
    st.markdown("### â³ å‡¦ç†ä¸­...")
    
    # é€²æ—æƒ…å ±å–å¾—
    progress_info = st.session_state.get('batch_progress', {})
    
    # å…¨ä½“é€²æ—
    total_files = progress_info.get('total_files', 0)
    processed_files = progress_info.get('processed_files', 0)
    
    if total_files > 0:
        progress = processed_files / total_files
        st.progress(progress)
        st.text(f"é€²æ—: {processed_files}/{total_files} ({progress*100:.0f}%)")
    
    # è©³ç´°æƒ…å ±
    if progress_info:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("å‡¦ç†æ¸ˆã¿", processed_files)
        
        with col2:
            st.metric("æˆåŠŸ", progress_info.get('successful', 0))
        
        with col3:
            st.metric("ã‚¨ãƒ©ãƒ¼", progress_info.get('errors', 0))
        
        # ç¾åœ¨å‡¦ç†ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«
        current_file = progress_info.get('current_file')
        if current_file:
            st.text(f"å‡¦ç†ä¸­: {current_file}")
        
        # çµŒéæ™‚é–“
        start_time = progress_info.get('start_time')
        if start_time:
            elapsed = time.time() - start_time
            st.text(f"çµŒéæ™‚é–“: {elapsed:.0f}ç§’")

def show_batch_summary():
    """ãƒãƒƒãƒå‡¦ç†ã‚µãƒãƒªãƒ¼ã‚’è¡¨ç¤º"""
    
    st.markdown("### ğŸ“ˆ å‡¦ç†ã‚µãƒãƒªãƒ¼")
    
    # æœ€å¾Œã®å‡¦ç†çµæœ
    last_batch = st.session_state.get('last_batch_result')
    
    if last_batch:
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°", last_batch.get('total_files', 0))
        
        with col2:
            st.metric("æˆåŠŸç‡", f"{last_batch.get('success_rate', 0):.1%}")
        
        with col3:
            st.metric("å‡¦ç†æ™‚é–“", f"{last_batch.get('total_time', 0):.0f}ç§’")
        
        # ã‚¨ãƒ©ãƒ¼æƒ…å ±
        errors = last_batch.get('errors', [])
        if errors:
            with st.expander(f"âš ï¸ ã‚¨ãƒ©ãƒ¼è©³ç´° ({len(errors)}ä»¶)", expanded=False):
                for error in errors[:10]:  # æœ€å¤§10ä»¶è¡¨ç¤º
                    st.text(f"âŒ {error.get('file', 'ä¸æ˜')}: {error.get('error', 'ã‚¨ãƒ©ãƒ¼è©³ç´°ãªã—')}")
    else:
        st.info("ã¾ã ãƒãƒƒãƒå‡¦ç†ãŒå®Ÿè¡Œã•ã‚Œã¦ã„ã¾ã›ã‚“")

def show_recent_batch_history():
    """æœ€è¿‘ã®ãƒãƒƒãƒå±¥æ­´ã‚’è¡¨ç¤º"""
    
    with st.expander("ğŸ“ æœ€è¿‘ã®ãƒãƒƒãƒå±¥æ­´", expanded=False):
        try:
            config = st.session_state.config
            if config:
                agent = create_agent_from_config(config)
                history = agent.get_batch_history(limit=5)
                
                if history:
                    history_data = []
                    for item in history:
                        history_data.append({
                            "å®Ÿè¡Œæ—¥æ™‚": datetime.fromisoformat(item['created_at']).strftime("%Y-%m-%d %H:%M"),
                            "ãƒ•ã‚¡ã‚¤ãƒ«æ•°": item['total_files'],
                            "æˆåŠŸ": item['successful_files'],
                            "ã‚¨ãƒ©ãƒ¼": item['error_files'],
                            "å‡¦ç†æ™‚é–“": f"{item['total_time']:.0f}ç§’"
                        })
                    
                    df = pd.DataFrame(history_data)
                    st.dataframe(df, use_container_width=True, hide_index=True)
                else:
                    st.info("ãƒãƒƒãƒå‡¦ç†å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        except Exception as e:
            st.error(f"å±¥æ­´å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

def show_batch_results_tab():
    """ãƒãƒƒãƒå‡¦ç†çµæœã‚¿ãƒ–"""
    
    st.subheader("ğŸ“Š ãƒãƒƒãƒå‡¦ç†çµæœ")
    
    # çµæœãŒå­˜åœ¨ã™ã‚‹å ´åˆ
    if 'batch_results' in st.session_state:
        results = st.session_state.batch_results
        
        # çµæœã‚µãƒãƒªãƒ¼
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°", results['total_files'])
        
        with col2:
            st.metric("æˆåŠŸ", results['successful_files'])
        
        with col3:
            st.metric("ã‚¨ãƒ©ãƒ¼", results['error_files'])
        
        with col4:
            st.metric("å‡¦ç†æ™‚é–“", f"{results['total_time']:.0f}ç§’")
        
        # çµæœè©³ç´°
        st.markdown("### ğŸ“‹ å‡¦ç†çµæœè©³ç´°")
        
        if results.get('file_results'):
            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
            result_data = []
            for file_result in results['file_results']:
                result_data.append({
                    'ãƒ•ã‚¡ã‚¤ãƒ«å': Path(file_result['file_path']).name,
                    'çŠ¶æ…‹': 'æˆåŠŸ' if file_result['success'] else 'ã‚¨ãƒ©ãƒ¼',
                    'ä¿¡é ¼åº¦': f"{file_result.get('confidence_score', 0):.1%}",
                    'å‡¦ç†æ™‚é–“': f"{file_result.get('processing_time', 0):.1f}ç§’",
                    'ã‚¨ãƒ©ãƒ¼è©³ç´°': file_result.get('error', '-')
                })
            
            df = pd.DataFrame(result_data)
            st.dataframe(df, use_container_width=True)
            
            # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã‚ªãƒ—ã‚·ãƒ§ãƒ³
            st.markdown("### ğŸ’¾ çµæœã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("ğŸ“¥ Excelå‡ºåŠ›", use_container_width=True):
                    DataExporter.export_to_excel(df, "batch_results.xlsx")
            
            with col2:
                if st.button("ğŸ“¥ CSVå‡ºåŠ›", use_container_width=True):
                    DataExporter.export_to_csv(df, "batch_results.csv")
            
            with col3:
                if st.button("ğŸ“¥ JSONå‡ºåŠ›", use_container_width=True):
                    DataExporter.export_to_json(results, "batch_results.json")
        else:
            st.info("è©³ç´°ãªå‡¦ç†çµæœãŒã‚ã‚Šã¾ã›ã‚“")
    else:
        st.info("ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã¨çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™")

def show_batch_statistics_tab():
    """ãƒãƒƒãƒå‡¦ç†çµ±è¨ˆã‚¿ãƒ–"""
    
    st.subheader("ğŸ“ˆ å‡¦ç†çµ±è¨ˆ")
    
    try:
        config = st.session_state.config
        if config:
            agent = create_agent_from_config(config)
            stats = agent.get_batch_statistics()
            
            if stats:
                # åŸºæœ¬çµ±è¨ˆ
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("ç·å‡¦ç†æ•°", stats['total_batches'])
                
                with col2:
                    st.metric("ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°", stats['total_files'])
                
                with col3:
                    success_rate = stats['successful_files'] / stats['total_files'] if stats['total_files'] > 0 else 0
                    st.metric("å¹³å‡æˆåŠŸç‡", f"{success_rate:.1%}")
                
                with col4:
                    avg_time = stats['total_processing_time'] / stats['total_files'] if stats['total_files'] > 0 else 0
                    st.metric("å¹³å‡å‡¦ç†æ™‚é–“", f"{avg_time:.1f}ç§’/ãƒ•ã‚¡ã‚¤ãƒ«")
                
                # æ™‚ç³»åˆ—ãƒãƒ£ãƒ¼ãƒˆ
                if 'time_series_data' in stats:
                    st.markdown("### ğŸ“Š å‡¦ç†æ¨ç§»")
                    
                    df = pd.DataFrame(stats['time_series_data'])
                    df['date'] = pd.to_datetime(df['date'])
                    
                    StatisticsChart.show_time_series(
                        df,
                        'date',
                        'processed_files',
                        "æ—¥åˆ¥å‡¦ç†ãƒ•ã‚¡ã‚¤ãƒ«æ•°"
                    )
                
                # å‡¦ç†æ™‚é–“åˆ†å¸ƒ
                if 'processing_times' in stats:
                    st.markdown("### ğŸ“Š å‡¦ç†æ™‚é–“åˆ†å¸ƒ")
                    
                    StatisticsChart.show_distribution(
                        stats['processing_times'],
                        "å‡¦ç†æ™‚é–“åˆ†å¸ƒ"
                    )
                
                # ã‚¨ãƒ©ãƒ¼åˆ†æ
                if 'error_types' in stats:
                    st.markdown("### ğŸ“Š ã‚¨ãƒ©ãƒ¼åˆ†æ")
                    
                    error_data = stats['error_types']
                    StatisticsChart.show_comparison(
                        list(error_data.keys()),
                        list(error_data.values()),
                        "ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—åˆ¥ç™ºç”Ÿæ•°"
                    )
            else:
                st.info("çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    except Exception as e:
        st.error(f"çµ±è¨ˆå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

def execute_batch_processing(input_directory: str, output_directory: str, options: dict):
    """ãƒãƒƒãƒå‡¦ç†ã‚’å®Ÿè¡Œ"""
    
    try:
        # è¨­å®šç¢ºèª
        config = st.session_state.config
        if not config:
            raise ValueError("ã‚·ã‚¹ãƒ†ãƒ è¨­å®šãŒèª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
        
        api_key = config.get('openai.api_key')
        if not api_key or api_key == 'your-openai-api-key-here':
            raise ValueError("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šãƒšãƒ¼ã‚¸ã§è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        
        # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç¢ºèª
        input_path = Path(input_directory)
        if not input_path.exists():
            raise ValueError(f"å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {input_directory}")
        
        # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        output_path = Path(output_directory)
        output_path.mkdir(parents=True, exist_ok=True)
        
        # ãƒãƒƒãƒå‡¦ç†é–‹å§‹
        st.session_state.batch_processing = True
        st.session_state.batch_progress = {
            'total_files': 0,
            'processed_files': 0,
            'successful': 0,
            'errors': 0,
            'start_time': time.time()
        }
        
        # ãƒãƒƒãƒãƒ—ãƒ­ã‚»ãƒƒã‚µåˆæœŸåŒ–
        processor = BatchProcessor(
            agent=create_agent_from_config(config),
            batch_size=options['batch_size'],
            max_workers=options['max_workers'],
            timeout_minutes=options['timeout_minutes'],
            retry_attempts=options['retry_attempts']
        )
        
        # å‡¦ç†å®Ÿè¡Œ
        results = processor.process_directory(
            input_directory=input_directory,
            output_directory=output_directory,
            auto_product_type=options['auto_product_type'],
            default_product_type=options['default_product_type'],
            error_handling=options['error_handling'],
            output_formats=options['output_formats'],
            progress_callback=update_progress
        )
        
        # çµæœä¿å­˜
        st.session_state.batch_results = results
        st.session_state.last_batch_result = {
            'total_files': results['total_files'],
            'success_rate': results['successful_files'] / results['total_files'] if results['total_files'] > 0 else 0,
            'total_time': results['total_time'],
            'errors': [
                {'file': r['file_path'], 'error': r['error']}
                for r in results.get('file_results', [])
                if not r['success']
            ]
        }
        
        # å‡¦ç†å®Œäº†
        st.session_state.batch_processing = False
        NotificationManager.show_success("ãƒãƒƒãƒå‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ")
        
        # çµæœã‚¿ãƒ–ã«åˆ‡ã‚Šæ›¿ãˆ
        st.session_state.active_batch_tab = "ğŸ“Š å‡¦ç†çµæœ"
        st.rerun()
        
    except Exception as e:
        st.session_state.batch_processing = False
        NotificationManager.show_error(f"ãƒãƒƒãƒå‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")

def update_progress(progress_info: dict):
    """é€²æ—æƒ…å ±ã‚’æ›´æ–°"""
    
    st.session_state.batch_progress.update(progress_info)
